---
title: "H_Simulation_Analysis"
author: "Tyler M. Wiles"
date: "2025-11-20"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Description

# Simulation

Analysis of data obtained from our simulations

## Libraries and Data Management

```{r Libraries and Data Management}

options(scipen = 999)
rm(list=ls())

library(data.table)
library(here)
library(ggplot2)
library(ggridges)

files = list.files(path = here::here('DATA', 'H_Simulation'), pattern = "^H_Simulation[0-9]+(_[0-9]+)?\\.csv$", full.names = TRUE)
dat = rbindlist(lapply(files, data.table::fread))
dat = dat[ ,-1]

setnames(dat, old = c('h.original', 'h.test.random', 'h.test.contiguous'),
         new = c('original', 'random', 'contiguous'))

dat$random.diff = dat$random - dat$original
dat$contiguous.diff = dat$contiguous - dat$original

dat.long = melt(dat,
                measure.vars = tail(names(dat), 5),
                variable.name = "data.version",
                value.name   = "h.value")

# Easier to see/compare results with the differences rather than raw values
dat.long = dat.long[!(dat.long$data.version %in% c('original', 'random', 'contiguous')), ]

dat.long$drops = dat.long$drops * 100 # Change to percent

# Factors
dat.long$stride.intervals = factor(dat.long$stride.intervals)
dat.long$drops = factor(dat.long$drops)
dat.long$stride.intervals.cut = factor(dat.long$stride.intervals.cut)
dat.long$stride.intervals.new.length = factor(dat.long$stride.intervals.new.length)
dat.long$h.target = factor(dat.long$h.target, levels = rev(levels(factor(dat.long$h.target))))
dat.long$data.version = factor(dat.long$data.version)

dat.long$h.value.abs = abs(dat.long$h.value)

```

## BFTests

Using Bayesian ttests, is H obtained from the dropped time series different from zero?

```{r BFTests}

library(dplyr)
library(BayesFactor)

bf.abs = dat.long %>%
  group_by(h.target, stride.intervals, drops, data.version) %>%
  summarise(mu = mean(h.value.abs),
            ci.lower = bayestestR::ci(h.value.abs, method = 'hdi', ci = 0.95)$CI_low,
            ci.upper = bayestestR::ci(h.value.abs, method = 'hdi', ci = 0.95)$CI_high,
            BF10 = BayesFactor::extractBF(BayesFactor::ttestBF(x = h.value.abs, mu = 0))$bf,
            .groups = "drop")

bf.rel = dat.long %>%
  group_by(h.target, stride.intervals, drops, data.version) %>%
  summarise(mu = mean(h.value),
            ci.lower = bayestestR::ci(h.value, method = 'hdi', ci = 0.95)$CI_low,
            ci.upper = bayestestR::ci(h.value, method = 'hdi', ci = 0.95)$CI_high,
            BF10 = BayesFactor::extractBF(BayesFactor::ttestBF(x = h.value, mu = 0))$bf,
            .groups = "drop")

library(dplyr)
library(purrr)
library(tidyr)
library(DFBA)
bf.rel = dat.long %>%
  group_by(h.target, stride.intervals, drops, data.version) %>%
  group_split() %>%
  map_df(function(df) {
    y2 = df$h.value
    mu = rep(0, length(y2))
    
    res = DFBA::dfba_wilcoxon(Y1 = mu, Y2 = y2)
    
    tibble(h.target = unique(df$h.target),
           stride.intervals = unique(df$stride.intervals),
           drops = unique(df$drops),
           data.version = unique(df$data.version),
           bayes_factor = res$BF10,
           mu = mean(df$h.value),
           std = sd(df$h.value),
           ci.lower = bayestestR::ci(df$h.value, method = 'hdi', ci = 0.95)$CI_low,
           ci.upper = bayestestR::ci(df$h.value, method = 'hdi', ci = 0.95)$CI_high,)
  })

bf.abs = dat.long %>%
  group_by(h.target, stride.intervals, drops, data.version) %>%
  group_split() %>%
  map_df(function(df) {
    y2 = df$h.value.abs
    mu = rep(0, length(y2))
    
    res = DFBA::dfba_wilcoxon(Y1 = mu, Y2 = y2)
    
    tibble(h.target = unique(df$h.target),
           stride.intervals = unique(df$stride.intervals),
           drops = unique(df$drops),
           data.version = unique(df$data.version),
           bayes_factor = res$BF10,
           mu = mean(df$h.value.abs),
           std = sd(df$h.value.abs),
           ci.lower = bayestestR::ci(df$h.value.abs, method = 'hdi', ci = 0.95)$CI_low,
           ci.upper = bayestestR::ci(df$h.value.abs, method = 'hdi', ci = 0.95)$CI_high,)
  })

# Frequentist
wilcoxon.rel = dat.long %>%
  dplyr::group_by(h.target, stride.intervals, drops, data.version) %>%
  rstatix::wilcox_test(h.value ~ 1, mu = 0) %>%
  rstatix::add_significance()

wilcoxon.abs = dat.long %>%
  dplyr::group_by(h.target, stride.intervals, drops, data.version) %>%
  rstatix::wilcox_test(h.value.abs ~ 1, mu = 0) %>%
  rstatix::add_significance()

```

## Plots

### Absolute

```{r Absolute}

ci95 = dat.long |>
  dplyr::group_by(data.version, h.target, stride.intervals, drops) |>
  dplyr::summarise(h.mean = mean(h.value.abs, na.rm = TRUE),
                   h.median = median(h.value.abs, na.rm = TRUE),
                   .groups = "drop")

# Define line types that get more dashed with larger drops
linetypes = c("solid", "88", "66", "44", "22", "11")
linetype_map = setNames(rep(linetypes, length.out = length(unique(dat.long$drops))),
                        sort(unique(dat.long$drops)))

plot.sim.abs = ggplot(dat.long, aes(x = h.value.abs, fill = data.version)) +
  # Beautifying
  theme_classic() +
  scale_x_continuous(limits = c(0, 0.15),
                     breaks = c(0, 0.05, 0.10, 0.15)) +
  # Raw data
  geom_density(alpha = 0.3, adjust = 1, show.legend = TRUE) +
  # Mean lines with varying dash intensity by drops
  geom_vline(data = ci95, aes(xintercept = h.mean,
                              color = data.version,
                              linetype = factor(drops)),
             linewidth = 0.6,
             show.legend = TRUE) +
  scale_linetype_manual(values = linetype_map,
                        name = "Dropped Data (%)") +
  # More beautifying
  scale_fill_manual(values = c("random.diff" = scales::alpha("#FA4616", 0.1),
                               "contiguous.diff" = scales::alpha("#0021A5", 0.1)),
                    name = "Data Version",
                    labels = c("Random", "Contiguous")) +
  scale_color_manual(values = c("random.diff" = "#FA4616",
                                "contiguous.diff" = "#0021A5"),
                     guide = "none") +
  labs(x = "Difference from Original Hurst Exponent (Dropped - Original)",
       y = "Density") +
  facet_grid(rows = vars(h.target),
             cols = vars(stride.intervals),
             labeller = labeller(h.target = function(x) paste0("H = ", x),
                                 stride.intervals = function(x) paste0(x, " Stride Intervals")),
             axes = "all_x") +
  theme(legend.position = "top",
        text = element_text(size = 9),
        axis.text.x = element_text(size = 7),
        axis.text.y = element_text(size = 7))

ggsave(filename = 'C:/Users/twiles/Downloads/sim_abs.jpeg', plot = plot.sim.abs,
       height = 9, units = 'in', dpi = "retina", bg = "white")

```

### Relative

```{r Relative}

ci95 = dat.long |>
  dplyr::group_by(data.version, h.target, stride.intervals, drops) |>
  dplyr::summarise(h.mean = mean(h.value, na.rm = TRUE),
                   h.median = median(h.value, na.rm = TRUE),
                   .groups = "drop")

# Define line types that get more dashed with larger drops
linetypes = c("solid", "88", "66", "44", "22", "11")
linetype_map = setNames(rep(linetypes, length.out = length(unique(dat.long$drops))),
                        sort(unique(dat.long$drops)))

plot.sim.rel = ggplot(dat.long, aes(x = h.value, fill = data.version)) +
  # Beautifying
  theme_classic() +
  scale_x_continuous(limits = c(-0.15, 0.15),
                     breaks = c(-0.15, -0.10, -0.05, 0, 0.05, 0.10, 0.15)) +
  # Raw data
  geom_density(alpha = 0.3, adjust = 1, show.legend = TRUE) +
  # Mean lines with varying dash intensity by drops
  geom_vline(data = ci95, aes(xintercept = h.mean,
                              color = data.version,
                              linetype = factor(drops)),
             linewidth = 0.6,
             show.legend = TRUE) +
  scale_linetype_manual(values = linetype_map,
                        name = "Dropped Data (%)") +
  # More beautifying
  scale_fill_manual(values = c("random.diff" = scales::alpha("#FA4616", 0.1),
                               "contiguous.diff" = scales::alpha("#0021A5", 0.1)),
                    name = "Data Version",
                    labels = c("Random", "Contiguous")) +
  scale_color_manual(values = c("random.diff" = "#FA4616",
                                "contiguous.diff" = "#0021A5"),
                     guide = "none") +
  labs(x = "Difference from Original Hurst Exponent (Dropped - Original)",
       y = "Density") +
  facet_grid(rows = vars(h.target),
             cols = vars(stride.intervals),
             labeller = labeller(h.target = function(x) paste0("H = ", x),
                                 stride.intervals = function(x) paste0(x, " Stride Intervals")),
             axes = "all_x") +
  theme(legend.position = "top",
        text = element_text(size = 9),
        axis.text.x = element_text(size = 7, angle = 30, hjust = 1),
        axis.text.y = element_text(size = 7))

ggsave(filename = 'C:/Users/twiles/Downloads/sim_rel.jpeg', plot = plot.sim.rel,
       height = 9, units = 'in', dpi = "retina", bg = "white")

```

# Empirical

## Gaitprint

Analysis of data obtained from Gaitprint

### Libraries and Data Management

```{r Libraries and Data Management}

options(scipen = 999)
rm(list=ls())

library(data.table)
library(here)
library(ggplot2)
library(ggridges)

dat = data.table::fread(here::here('DATA', 'H_Simulation', 'H_Simulation_Gaitprint_Results.csv'))

setnames(dat, old = c('h.original', 'h.random', 'h.contiguous'),
         new = c('original', 'random', 'contiguous'))

dat$random.diff = dat$random - dat$original
dat$contiguous.diff = dat$contiguous - dat$original

dat.long = melt(dat,
                measure.vars = tail(names(dat), 5),
                variable.name = "data.version",
                value.name   = "h.value")

# Easier to see/compare results with the differences rather than raw values
dat.long = dat.long[!(dat.long$data.version %in% c('original', 'random', 'contiguous')), ]

dat.long$drops = dat.long$drops * 100 # Change to percent

dat.long = dat.long[!is.nan(stride.intervals)] # Remove skipped trials

# Factors
dat.long$id = factor(dat.long$id)
# dat.long$stride.intervals = factor(dat.long$stride.intervals)
dat.long$drops = factor(dat.long$drops)
dat.long$stride.intervals.cut = factor(dat.long$stride.intervals.cut)
dat.long$stride.intervals.new.length = factor(dat.long$stride.intervals.new.length)
dat.long$data.version = factor(dat.long$data.version)

dat.long$h.value.abs = abs(dat.long$h.value)

```

### BFTests

Using Bayesian ttests, is H obtained from the dropped time series different from zero?

```{r BFTests}

library(dplyr)
library(BayesFactor)

bf.abs = dat.long %>%
  group_by(h.target, stride.intervals, drops, data.version) %>%
  summarise(mu = mean(h.value.abs),
            ci.lower = bayestestR::ci(h.value.abs, method = 'hdi', ci = 0.95)$CI_low,
            ci.upper = bayestestR::ci(h.value.abs, method = 'hdi', ci = 0.95)$CI_high,
            BF10 = BayesFactor::extractBF(BayesFactor::ttestBF(x = h.value.abs, mu = 0))$bf,
            .groups = "drop")

bf.rel = dat.long %>%
  group_by(h.target, stride.intervals, drops, data.version) %>%
  summarise(mu = mean(h.value),
            ci.lower = bayestestR::ci(h.value, method = 'hdi', ci = 0.95)$CI_low,
            ci.upper = bayestestR::ci(h.value, method = 'hdi', ci = 0.95)$CI_high,
            BF10 = BayesFactor::extractBF(BayesFactor::ttestBF(x = h.value, mu = 0))$bf,
            .groups = "drop")

library(dplyr)
library(purrr)
library(tidyr)
library(DFBA)
bf.rel = dat.long %>%
  group_by(h.target, stride.intervals, drops, data.version) %>%
  group_split() %>%
  map_df(function(df) {
    y2 = df$h.value
    mu = rep(0, length(y2))
    
    res = DFBA::dfba_wilcoxon(Y1 = mu, Y2 = y2)
    
    tibble(h.target = unique(df$h.target),
           stride.intervals = unique(df$stride.intervals),
           drops = unique(df$drops),
           data.version = unique(df$data.version),
           bayes_factor = res$BF10,
           mu = mean(df$h.value),
           std = sd(df$h.value),
           ci.lower = bayestestR::ci(df$h.value, method = 'hdi', ci = 0.95)$CI_low,
           ci.upper = bayestestR::ci(df$h.value, method = 'hdi', ci = 0.95)$CI_high,)
  })

bf.abs = dat.long %>%
  group_by(h.target, stride.intervals, drops, data.version) %>%
  group_split() %>%
  map_df(function(df) {
    y2 = df$h.value.abs
    mu = rep(0, length(y2))
    
    res = DFBA::dfba_wilcoxon(Y1 = mu, Y2 = y2)
    
    tibble(h.target = unique(df$h.target),
           stride.intervals = unique(df$stride.intervals),
           drops = unique(df$drops),
           data.version = unique(df$data.version),
           bayes_factor = res$BF10,
           mu = mean(df$h.value.abs),
           std = sd(df$h.value.abs),
           ci.lower = bayestestR::ci(df$h.value.abs, method = 'hdi', ci = 0.95)$CI_low,
           ci.upper = bayestestR::ci(df$h.value.abs, method = 'hdi', ci = 0.95)$CI_high,)
  })

# Frequentist
wilcoxon.rel = dat.long %>%
  dplyr::group_by(h.target, stride.intervals, drops, data.version) %>%
  rstatix::wilcox_test(h.value ~ 1, mu = 0) %>%
  rstatix::add_significance()

wilcoxon.abs = dat.long %>%
  dplyr::group_by(h.target, stride.intervals, drops, data.version) %>%
  rstatix::wilcox_test(h.value.abs ~ 1, mu = 0) %>%
  rstatix::add_significance()

```

### Plots

#### Absolute

```{r Absolute}

ci95 = dat.long |>
  dplyr::group_by(data.version, stride.intervals, drops) |>
  dplyr::summarise(h.mean = mean(h.value.abs, na.rm = TRUE),
                   h.median = median(h.value.abs, na.rm = TRUE),
                   .groups = "drop")

# Define line types that get more dashed with larger drops
linetypes = c("solid", "88", "66", "44", "22", "11")
linetype_map = setNames(rep(linetypes, length.out = length(unique(dat.long$drops))),
                        sort(unique(dat.long$drops)))

plot.gaitprint.abs = ggplot(dat.long, aes(x = h.value.abs, fill = data.version)) +
  # Beautifying
  theme_classic() +
  scale_x_continuous(limits = c(0, 0.15),
                     breaks = c(0, 0.05, 0.10, 0.15)) +
  # Raw data
  geom_density(alpha = 0.3, adjust = 1, show.legend = TRUE) +
  # Mean lines with varying dash intensity by drops
  geom_vline(data = ci95, aes(xintercept = h.mean,
                              color = data.version,
                              linetype = factor(drops)),
             linewidth = 0.6,
             show.legend = TRUE) +
  scale_linetype_manual(values = linetype_map,
                        name = "Dropped Data (%)") +
  # More beautifying
  scale_fill_manual(values = c("random.diff" = scales::alpha("#FA4616", 0.1),
                               "contiguous.diff" = scales::alpha("#0021A5", 0.1)),
                    name = "Data Version",
                    labels = c("Random", "Contiguous")) +
  scale_color_manual(values = c("random.diff" = "#FA4616",
                                "contiguous.diff" = "#0021A5"),
                     guide = "none") +
  labs(x = "Absolute Difference from Original Hurst Exponent (Dropped - Original)",
       y = "Density") +
  facet_grid(rows = vars(drops),
             cols = vars(stride.intervals),
             labeller = labeller(stride.intervals = function(x) paste0(x, " Stride Intervals")),
             axes = "all_x") +
  theme(legend.position = "top",
        text = element_text(size = 9),
        axis.text.x = element_text(size = 7),
        axis.text.y = element_text(size = 7))

ggsave(filename = 'C:/Users/twiles/Downloads/gaitprint_abs.jpeg', plot = plot.gaitprint.abs,
       height = 9, units = 'in', dpi = "retina", bg = "white")

```

#### Relative

```{r Relative}

ci95 = dat.long |>
  dplyr::group_by(data.version, stride.intervals, drops) |>
  dplyr::summarise(h.mean = mean(h.value, na.rm = TRUE),
                   h.median = median(h.value, na.rm = TRUE),
                   .groups = "drop")

# Define line types that get more dashed with larger drops
linetypes = c("solid", "88", "66", "44", "22", "11")
linetype_map = setNames(rep(linetypes, length.out = length(unique(dat.long$drops))),
                        sort(unique(dat.long$drops)))

plot.gaitprint.rel = ggplot(dat.long, aes(x = h.value, fill = data.version)) +
  # Beautifying
  theme_classic() +
  scale_x_continuous(limits = c(-0.15, 0.15),
                     breaks = c(-0.15, -0.10, -0.05, 0, 0.05, 0.10, 0.15)) +
  # Raw data
  geom_density(alpha = 0.3, adjust = 1, show.legend = TRUE) +
  # Mean lines with varying dash intensity by drops
  geom_vline(data = ci95, aes(xintercept = h.mean,
                              color = data.version,
                              linetype = factor(drops)),
             linewidth = 0.6,
             show.legend = TRUE) +
  scale_linetype_manual(values = linetype_map,
                        name = "Dropped Data (%)") +
  # More beautifying
  scale_fill_manual(values = c("random.diff" = scales::alpha("#FA4616", 0.1),
                               "contiguous.diff" = scales::alpha("#0021A5", 0.1)),
                    name = "Data Version",
                    labels = c("Random", "Contiguous")) +
  scale_color_manual(values = c("random.diff" = "#FA4616",
                                "contiguous.diff" = "#0021A5"),
                     guide = "none") +
  labs(x = "Difference from Original Hurst Exponent (Dropped - Original)",
       y = "Density") +
  facet_grid(rows = vars(drops),
             cols = vars(stride.intervals),
             labeller = labeller(stride.intervals = function(x) paste0(x, " Stride Intervals")),
             axes = "all_x") +
  theme(legend.position = "top",
        text = element_text(size = 9),
        axis.text.x = element_text(size = 7),
        axis.text.y = element_text(size = 7))

ggsave(filename = 'C:/Users/twiles/Downloads/gaitprint_rel.jpeg', plot = plot.gaitprint.rel,
       height = 9, units = 'in', dpi = "retina", bg = "white")

```

## MindinMotion

Analysis of data obtained from MindinMotion

### Libraries and Data Management

```{r Libraries and Data Management}

options(scipen = 999)
rm(list=ls())

library(BayesFactor)
library(data.table)
library(dplyr)
library(here)
library(ggplot2)
library(ggridges)
library(readxl)

dat = data.table::fread(here::here('DATA', 'H_Simulation', 'H_Simulation_MIM.csv'))

# Only include trials that did not have to contain dropped data due to missing contacts
dat.ref = data.table::fread(here::here('DATA', 'H_Simulation', 'H_Simulation_MIM_Results_Test.csv'))
dat.ref = dat.ref[dat.ref$n.intervals.dropped == 0]
dat = merge(dat, dat.ref[ ,1:5], by = c('id', 'treadmill', 'speed', 'terrain', 'trial'), all = FALSE)

dat = dat[!is.nan(stride.intervals)] # Remove skipped trials

setnames(dat, old = c('h.original', 'h.random', 'h.contiguous'),
         new = c('original', 'random', 'contiguous'))

dat$random.diff = dat$random - dat$original
dat$contiguous.diff = dat$contiguous - dat$original

dat.long = melt(dat,
                measure.vars = tail(names(dat), 5),
                variable.name = "data.version",
                value.name   = "h.value")

# Easier to see/compare results with the differences rather than raw values
dat.long = dat.long[!(dat.long$data.version %in% c('original', 'random', 'contiguous')), ]

dat.long$drops = dat.long$drops * 100 # Change to percent

dat.long = dat.long[!is.nan(stride.intervals)] # Remove skipped trials

# Factors
dat.long$id = factor(dat.long$id)
# dat.long$stride.intervals = factor(dat.long$stride.intervals)
dat.long$drops = factor(dat.long$drops)
dat.long$stride.intervals.cut = factor(dat.long$stride.intervals.cut)
dat.long$stride.intervals.new.length = factor(dat.long$stride.intervals.new.length)
dat.long$data.version = factor(dat.long$data.version)

dat.long$h.value.abs = abs(dat.long$h.value)

```

### BFTests

Using Bayesian ttests, is H obtained from the dropped time series different from zero?

```{r BFTests}

library(dplyr)
library(BayesFactor)

bf.abs = dat.long %>%
  group_by(h.target, stride.intervals, drops, data.version) %>%
  summarise(mu = mean(h.value.abs),
            ci.lower = bayestestR::ci(h.value.abs, method = 'hdi', ci = 0.95)$CI_low,
            ci.upper = bayestestR::ci(h.value.abs, method = 'hdi', ci = 0.95)$CI_high,
            BF10 = BayesFactor::extractBF(BayesFactor::ttestBF(x = h.value.abs, mu = 0))$bf,
            .groups = "drop")

bf.rel = dat.long %>%
  group_by(h.target, stride.intervals, drops, data.version) %>%
  summarise(mu = mean(h.value),
            ci.lower = bayestestR::ci(h.value, method = 'hdi', ci = 0.95)$CI_low,
            ci.upper = bayestestR::ci(h.value, method = 'hdi', ci = 0.95)$CI_high,
            BF10 = BayesFactor::extractBF(BayesFactor::ttestBF(x = h.value, mu = 0))$bf,
            .groups = "drop")

library(dplyr)
library(purrr)
library(tidyr)
library(DFBA)
bf.rel = dat.long %>%
  group_by(h.target, stride.intervals, drops, data.version) %>%
  group_split() %>%
  map_df(function(df) {
    y2 = df$h.value
    mu = rep(0, length(y2))
    
    res = DFBA::dfba_wilcoxon(Y1 = mu, Y2 = y2)
    
    tibble(h.target = unique(df$h.target),
           stride.intervals = unique(df$stride.intervals),
           drops = unique(df$drops),
           data.version = unique(df$data.version),
           bayes_factor = res$BF10,
           mu = mean(df$h.value),
           std = sd(df$h.value),
           ci.lower = bayestestR::ci(df$h.value, method = 'hdi', ci = 0.95)$CI_low,
           ci.upper = bayestestR::ci(df$h.value, method = 'hdi', ci = 0.95)$CI_high,)
  })

bf.abs = dat.long %>%
  group_by(h.target, stride.intervals, drops, data.version) %>%
  group_split() %>%
  map_df(function(df) {
    y2 = df$h.value.abs
    mu = rep(0, length(y2))
    
    res = DFBA::dfba_wilcoxon(Y1 = mu, Y2 = y2)
    
    tibble(h.target = unique(df$h.target),
           stride.intervals = unique(df$stride.intervals),
           drops = unique(df$drops),
           data.version = unique(df$data.version),
           bayes_factor = res$BF10,
           mu = mean(df$h.value.abs),
           std = sd(df$h.value.abs),
           ci.lower = bayestestR::ci(df$h.value.abs, method = 'hdi', ci = 0.95)$CI_low,
           ci.upper = bayestestR::ci(df$h.value.abs, method = 'hdi', ci = 0.95)$CI_high,)
  })

# Frequentist
wilcoxon.rel = dat.long %>%
  dplyr::group_by(h.target, stride.intervals, drops, data.version) %>%
  rstatix::wilcox_test(h.value ~ 1, mu = 0) %>%
  rstatix::add_significance()

wilcoxon.abs = dat.long %>%
  dplyr::group_by(h.target, stride.intervals, drops, data.version) %>%
  rstatix::wilcox_test(h.value.abs ~ 1, mu = 0) %>%
  rstatix::add_significance()

```

### Plots

#### Absolute

```{r Absolute}

ci95 = dat.long |>
  dplyr::group_by(data.version, stride.intervals, drops) |>
  dplyr::summarise(h.mean = mean(h.value.abs, na.rm = TRUE),
                   h.median = median(h.value.abs, na.rm = TRUE),
                   .groups = "drop")

# Define line types that get more dashed with larger drops
linetypes = c("solid", "88", "66", "44", "22", "11")
linetype_map = setNames(rep(linetypes, length.out = length(unique(dat.long$drops))),
                        sort(unique(dat.long$drops)))

plot.mim.abs = ggplot(dat.long, aes(x = h.value.abs, fill = data.version)) +
  # Beautifying
  theme_classic() +
  scale_x_continuous(limits = c(0, 0.15),
                     breaks = c(0, 0.05, 0.10, 0.15)) +
  # Raw data
  geom_density(alpha = 0.3, adjust = 1, show.legend = TRUE) +
  # Mean lines with varying dash intensity by drops
  geom_vline(data = ci95, aes(xintercept = h.mean,
                              color = data.version,
                              linetype = factor(drops)),
             linewidth = 0.6,
             show.legend = TRUE) +
  scale_linetype_manual(values = linetype_map,
                        name = "Dropped Data (%)") +
  # More beautifying
  scale_fill_manual(values = c("random.diff" = scales::alpha("#FA4616", 0.1),
                               "contiguous.diff" = scales::alpha("#0021A5", 0.1)),
                    name = "Data Version",
                    labels = c("Random", "Contiguous")) +
  scale_color_manual(values = c("random.diff" = "#FA4616",
                                "contiguous.diff" = "#0021A5"),
                     guide = "none") +
  labs(x = "Absoulte Difference from Original Hurst Exponent (Dropped - Original)",
       y = "Density") +
  facet_grid(rows = vars(drops),
             cols = vars(stride.intervals),
             labeller = labeller(stride.intervals = function(x) paste0(x, " Stride Intervals")),
             axes = "all_x") +
  theme(legend.position = "top",
        text = element_text(size = 9),
        axis.text.x = element_text(size = 7),
        axis.text.y = element_text(size = 7))

ggsave(filename = 'C:/Users/twiles/Downloads/mim_abs.jpeg', plot = plot.mim.abs,
       height = 9, units = 'in', dpi = "retina", bg = "white")

```

#### Relative

```{r Relative}

ci95 = dat.long |>
  dplyr::group_by(data.version, stride.intervals, drops) |>
  dplyr::summarise(h.mean = mean(h.value, na.rm = TRUE),
                   h.median = median(h.value, na.rm = TRUE),
                   .groups = "drop")

# Define line types that get more dashed with larger drops
linetypes = c("solid", "88", "66", "44", "22", "11")
linetype_map = setNames(rep(linetypes, length.out = length(unique(dat.long$drops))),
                        sort(unique(dat.long$drops)))

plot.mim.rel = ggplot(dat.long, aes(x = h.value, fill = data.version)) +
  # Beautifying
  theme_classic() +
  scale_x_continuous(limits = c(-0.15, 0.15),
                     breaks = c(-0.15, -0.10, -0.05, 0, 0.05, 0.10, 0.15)) +
  # Raw data
  geom_density(alpha = 0.3, adjust = 1, show.legend = TRUE) +
  # Mean lines with varying dash intensity by drops
  geom_vline(data = ci95, aes(xintercept = h.mean,
                              color = data.version,
                              linetype = factor(drops)),
             linewidth = 0.8,
             show.legend = TRUE) +
  scale_linetype_manual(values = linetype_map,
                        name = "Dropped Data (%)") +
  # More beautifying
  scale_fill_manual(values = c("random.diff" = scales::alpha("#FA4616", 0.1),
                               "contiguous.diff" = scales::alpha("#0021A5", 0.1)),
                    name = "Data Version",
                    labels = c("Random", "Contiguous")) +
  scale_color_manual(values = c("random.diff" = "#FA4616",
                                "contiguous.diff" = "#0021A5"),
                     guide = "none") +
  labs(x = "Difference from Original Hurst Exponent (Dropped - Original)",
       y = "Density") +
  facet_grid(rows = vars(drops),
             cols = vars(stride.intervals),
             labeller = labeller(stride.intervals = function(x) paste0(x, " Stride Intervals")),
             axes = "all_x") +
  theme(legend.position = "top",
        text = element_text(size = 9),
        axis.text.x = element_text(size = 7),
        axis.text.y = element_text(size = 7))

ggsave(filename = 'C:/Users/twiles/Downloads/mim_rel.jpeg', plot = plot.mim.rel,
       height = 9, units = 'in', dpi = "retina", bg = "white")

```

# MIM Hypothesis

Analysis of data obtained from MindinMotion

## Libraries and Data Management

```{r Libraries and Data Management}

options(scipen = 999)
rm(list=ls())

library(BayesFactor)
library(data.table)
library(dplyr)
library(here)
library(ggplot2)
library(ggridges)
library(readxl)

dat = data.table::fread(here::here('DATA', 'H_Simulation', 'H_Simulation_MIM_Results_Test.csv'))
dat.demographics = as.data.table(read_excel(here("DATA", "MiM_Crunch_demographics_Chang.xlsx"), sheet = 2))
dat.demographics = dat.demographics[ ,c(3,6:13)] # Remove unwanted columns

# Merge
dat = merge(dat, dat.demographics, by.x = "id", by.y = "subject_code", all.x = TRUE)

# Remove skipped trials/NaNs
dat = dat[!(is.nan(dat$hurst) | dat$hurst == "") | !(is.nan(dat$entropy) | dat$entropy == ""), ]

# Cleanup
setnames(dat, old = c("Age", "Sex(1=M,0=F)", "Handedness (1=R, 2=L)", 
                      "terrain_trials_speed_ms", "Moca", "SPPB", 
                      "400_meters_seconds", "400m_speed"),
         new = c("age", "sex", "handedness", "terrain.speed", 
                 "moca", "sppb", "time.400m", "speed.400m"))
dat$handedness = ifelse(dat$handedness == 1, "right", "left")
dat$sex = ifelse(dat$sex == 1, "male", "female")
dat$speed = gsub("p", ".", dat$speed)

dat$functioning = ifelse(dat$sppb < 10, "low.functioning", "high.functioning") # Low functioning defined as sppb < 10
dat$group = ifelse(dat$age < 50, "young", "old") # young adults are less than 50 years old

# Only include older adults because we know differences are likely between young and older adults
dat = dat[dat$group == 'old']

# Factors
dat$id = factor(dat$id)
dat$treadmill = factor(dat$treadmill)
dat$speed = factor(dat$speed)
dat$terrain = factor(dat$terrain)
dat$trial = factor(dat$trial)
dat$sex = factor(dat$sex)
dat$handedness = factor(dat$handedness)
dat$functioning = factor(dat$functioning)
dat$group = factor(dat$group)
dat$n.intervals.dropped = factor(dat$n.intervals.dropped)
dat$pct.timeseries.dropped = factor(dat$pct.timeseries.dropped)

```

## BFTests

```{r BFTests}

# Are there differences between levels of dropped data?
BayesFactor::anovaBF(hurst ~ n.intervals.dropped + id, data = dat, whichRandom = 'id')
BayesFactor::anovaBF(entropy ~ n.intervals.dropped + id, data = dat, whichRandom = 'id')

# Differences between participant features?
BayesFactor::anovaBF(hurst ~ speed * functioning * trial + id, data = dat, whichRandom = 'id')
BayesFactor::ttestBF(x = dat$hurst[dat$speed == '0.25' & dat$functioning == 'high.functioning'],
                     y = dat$hurst[dat$speed == '0.25' & dat$functioning == 'low.functioning'],
                     paired = FALSE)
BayesFactor::ttestBF(x = dat$hurst[dat$speed == '0.5' & dat$functioning == 'high.functioning'],
                     y = dat$hurst[dat$speed == '0.5' & dat$functioning == 'low.functioning'],
                     paired = FALSE)
BayesFactor::ttestBF(x = dat$hurst[dat$speed == '0.75' & dat$functioning == 'high.functioning'],
                     y = dat$hurst[dat$speed == '0.75' & dat$functioning == 'low.functioning'],
                     paired = FALSE)
BayesFactor::ttestBF(x = dat$hurst[dat$speed == '1.0' & dat$functioning == 'high.functioning'],
                     y = dat$hurst[dat$speed == '1.0' & dat$functioning == 'low.functioning'],
                     paired = FALSE)


summary(aov(hurst ~ speed * trial * functioning, data = dat))
t.test(x = dat$hurst[dat$speed == '0.25' & dat$functioning == 'high.functioning'],
       y = dat$hurst[dat$speed == '0.25' & dat$functioning == 'low.functioning'])
t.test(x = dat$hurst[dat$speed == '0.5' & dat$functioning == 'high.functioning'],
       y = dat$hurst[dat$speed == '0.5' & dat$functioning == 'low.functioning'])
t.test(x = dat$hurst[dat$speed == '0.75' & dat$functioning == 'high.functioning'],
       y = dat$hurst[dat$speed == '0.75' & dat$functioning == 'low.functioning'])
t.test(x = dat$hurst[dat$speed == '1.0' & dat$functioning == 'high.functioning'],
       y = dat$hurst[dat$speed == '1.0' & dat$functioning == 'low.functioning'])

```

```{r lm}

m0 = lm(hurst ~ 1 + speed * functioning * trial, data = dat)
summary(m0)



plot(dat$stride.intervals, dat$h.value.abs)
plot(dat$stride.intervals, dat$h.value)



m0 = lm(h.value.abs ~ 1 + drops * stride.intervals + data.version, data = dat)
summary(m0)
library(emmeans)
emm <- emmeans(m0, ~ data.version)
emm
contrast(emm, method = "eff")   # tests each level against zero







```


```{r brms}

library(brms)
library(cmdstanr)

m0 = brms::brm(hurst ~ 1 + speed * functioning * trial,
               data = dat,
               cores = parallel::detectCores() - 1,
               chains = 4,
               iter = 3000,
               threads = threading(4),
               backend = 'cmdstanr',
               stan_model_args = list(stanc_options = list('O1')),
               seed = 4172015,
               refresh = 1000)
m0
plot(m0)
conditional_effects(m0)

dat$moca = scale(dat$moca)
dat$sppb = scale(dat$sppb)
dat$time.400m = scale(dat$time.400m)

m0 = brms::brm(hurst ~ functioning * moca * sppb * time.400m,
               data = dat,
               cores = parallel::detectCores() - 1,
               chains = 4,
               iter = 3000,
               threads = threading(4),
               backend = 'cmdstanr',
               stan_model_args = list(stanc_options = list('O1')),
               seed = 4172015,
               refresh = 1000)
m0
plot(m0)
conditional_effects(m0)


m0 = brms::brm(h.value.abs ~ stride.intervals * drops * data.version,
               data = dat,
               cores = parallel::detectCores(),
               chains = 4,
               iter = 3000,
               threads = threading(4),
               backend = 'cmdstanr',
               stan_model_args = list(stanc_options = list('O1')),
               seed = 4172015,
               refresh = 1000)





print(summary(m3), digits = 5)

loo(m1, m2, m3, compare = TRUE)

save(m1, m2, m3, file = here('DATA', 'temperature_brms_diff.RData'))

emmeans::emtrends(m3, pairwise ~ mitten | condition, var = 'time_poly2')
emmeans::emtrends(m3, pairwise ~ mitten | condition, var = 'time_poly3')



```

## Plots

### Trial Differences

```{r Trial Differences}

ci95 = dat |>
  dplyr::group_by(speed, trial) |>
  dplyr::summarise(hurst.mean = mean(hurst, na.rm = TRUE),
                   hurst.ci.lower = bayestestR::ci(hurst, method = 'hdi', ci = 0.95)$CI_low,
                   hurst.ci.upper = bayestestR::ci(hurst, method = 'hdi', ci = 0.95)$CI_high,
                   entropy.mean = mean(entropy, na.rm = TRUE),
                   entropy.ci.lower = bayestestR::ci(entropy, method = 'hdi', ci = 0.95)$CI_low,
                   entropy.ci.upper = bayestestR::ci(entropy, method = 'hdi', ci = 0.95)$CI_high,
                   .groups = "drop")

hursts = ggplot() +
  geom_point(data = dat, aes(x = speed,
                             y = hurst,
                             group = trial),
             color = 'black', size = 1,
             position = position_jitterdodge(jitter.width = 0.15,
                                             dodge.width = 0.7)) +
  # colored lines connecting condition means
  geom_line(data = ci95, aes(x = speed,
                             y = hurst.mean,
                             color = trial,
                             group = trial),
            linewidth = 1.2, position = position_dodge(width = 0.7)) +
  # colored mean points
  geom_point(data = ci95, aes(x = speed,
                              y = hurst.mean,
                              color = trial),
             size = 4, position = position_dodge(width = 0.7)) +
  # 95% credible intervals (HDI)
  geom_errorbar(data = ci95, aes(x = speed,
                                 ymin = hurst.ci.lower,
                                 ymax = hurst.ci.upper,
                                 color = trial),
                width = 0.6, linewidth = 1, position = position_dodge(width = 0.7)) +
  # Beautify
  labs(x = "Speed (m/s)", y = "Hurst Exponent", color = 'Trial') +
  scale_color_manual(values = c("1" = "#D71920", "2" = "#2C3FDE"),
                     labels = c("Trial 1", "Trial 2")) +
  theme_classic() +
  theme(legend.position = "top") +
  ylim(0, 1)
ggsave(filename = 'C:/Users/tyler_3r9w1ip/Downloads/MIM_SP_hursts.jpeg', plot = hursts,
       dpi = "retina", bg = "white")

entropys = ggplot() +
  geom_point(data = dat, aes(x = speed,
                             y = entropy,
                             group = trial),
             color = 'black', size = 1,
             position = position_jitterdodge(jitter.width = 0.15,
                                             dodge.width = 0.7)) +
  # colored lines connecting condition means
  geom_line(data = ci95, aes(x = speed,
                             y = entropy.mean,
                             color = trial,
                             group = trial),
            linewidth = 1.2, position = position_dodge(width = 0.7)) +
  # colored mean points
  geom_point(data = ci95, aes(x = speed,
                              y = entropy.mean,
                              color = trial),
             size = 4, position = position_dodge(width = 0.7)) +
  # 95% credible intervals (HDI)
  geom_errorbar(data = ci95, aes(x = speed,
                                 ymin = entropy.ci.lower,
                                 ymax = entropy.ci.upper,
                                 color = trial),
                width = 0.6, linewidth = 1, position = position_dodge(width = 0.7)) +
  # Beautify
  labs(x = "Speed (m/s)", y = "Sample Entropy", color = 'Trial') +
  scale_color_manual(values = c("1" = "#D71920", "2" = "#2C3FDE"),
                     labels = c("Trial 1", "Trial 2")) +
  theme_classic() +
  theme(legend.position = "top")
ggsave(filename = 'C:/Users/tyler_3r9w1ip/Downloads/MIM_SP_entropys.jpeg', plot = entropys,
       dpi = "retina", bg = "white")

```

### Cognitive Function Differences

```{r Cognitive Function Differences}

ci95 = dat |>
  dplyr::group_by(speed, functioning) |>
  dplyr::summarise(hurst.mean = mean(hurst, na.rm = TRUE),
                   hurst.ci.lower = bayestestR::ci(hurst, method = 'hdi', ci = 0.95)$CI_low,
                   hurst.ci.upper = bayestestR::ci(hurst, method = 'hdi', ci = 0.95)$CI_high,
                   entropy.mean = mean(entropy, na.rm = TRUE),
                   entropy.ci.lower = bayestestR::ci(entropy, method = 'hdi', ci = 0.95)$CI_low,
                   entropy.ci.upper = bayestestR::ci(entropy, method = 'hdi', ci = 0.95)$CI_high,
                   .groups = "drop")

hursts = ggplot() +
  geom_point(data = dat, aes(x = speed,
                             y = hurst,
                             group = functioning),
             color = 'black', size = 1,
             position = position_jitterdodge(jitter.width = 0.15,
                                             dodge.width = 0.7)) +
  # colored lines connecting condition means
  geom_line(data = ci95, aes(x = speed,
                             y = hurst.mean,
                             color = functioning,
                             group = functioning),
            linewidth = 1.2, position = position_dodge(width = 0.7)) +
  # colored mean points
  geom_point(data = ci95, aes(x = speed,
                              y = hurst.mean,
                              color = functioning),
             size = 4, position = position_dodge(width = 0.7)) +
  # 95% credible intervals (HDI)
  geom_errorbar(data = ci95, aes(x = speed,
                                 ymin = hurst.ci.lower,
                                 ymax = hurst.ci.upper,
                                 color = functioning),
                width = 0.6, linewidth = 1, position = position_dodge(width = 0.7)) +
  # Beautify
  labs(x = "Speed (m/s)", y = "Hurst Exponent", color = 'Cognitive Function') +
  scale_color_manual(values = c("high.functioning" = "#D71920", "low.functioning" = "#2C3FDE"),
                     labels = c("High Functioning", "Low Functioning")) +
  theme_classic() +
  theme(legend.position = "top") +
  ylim(0, 1)
ggsave(filename = 'C:/Users/tyler_3r9w1ip/Downloads/MIM_SP_hursts.jpeg', plot = hursts,
       dpi = "retina", bg = "white")

entropys = ggplot() +
  geom_point(data = dat, aes(x = speed,
                             y = entropy,
                             group = functioning),
             color = 'black', size = 1,
             position = position_jitterdodge(jitter.width = 0.15,
                                             dodge.width = 0.7)) +
  # colored lines connecting condition means
  geom_line(data = ci95, aes(x = speed,
                             y = entropy.mean,
                             color = functioning,
                             group = functioning),
            linewidth = 1.2, position = position_dodge(width = 0.7)) +
  # colored mean points
  geom_point(data = ci95, aes(x = speed,
                              y = entropy.mean,
                              color = functioning),
             size = 4, position = position_dodge(width = 0.7)) +
  # 95% credible intervals (HDI)
  geom_errorbar(data = ci95, aes(x = speed,
                                 ymin = entropy.ci.lower,
                                 ymax = entropy.ci.upper,
                                 color = functioning),
                width = 0.6, linewidth = 1, position = position_dodge(width = 0.7)) +
  # Beautify
  labs(x = "Speed (m/s)", y = "Sample Entropy", color = 'Cognitive Function') +
  scale_color_manual(values = c("high.functioning" = "#D71920", "low.functioning" = "#2C3FDE"),
                     labels = c("High Functioning", "Low Functioning")) +
  theme_classic() +
  theme(legend.position = "top")
ggsave(filename = 'C:/Users/tyler_3r9w1ip/Downloads/MIM_SP_entropys.jpeg', plot = entropys,
       dpi = "retina", bg = "white")

```